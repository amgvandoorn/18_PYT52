---
title: "Clone clustering for RADAR selection"
author: "Anna Magdalena"
date: "3/24/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(dplyr)
require (tm)
require(plyr)
require(cluster)
require(readr)
require(here)
completeFun=function(data, desiredCols){ 
  completeVec=complete.cases(data[, desiredCols])
  return(data[completeVec,])
  }

detach("package:dplyr", unload=TRUE)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
  library(plyr)
  
  # New version of length which can handle NA's: if na.rm==T, don't count them
  length2 <- function (x, na.rm=FALSE) {
    if (na.rm) sum(!is.na(x))
    else       length(x)
  }
  
  # This does the summary. For each group's data frame, return a vector with
  # N, mean, and sd
  
  datac <- ddply(data, groupvars, .drop=.drop,
                 .fun = function(xx, col) {
                   c(N    = length2(xx[[col]], na.rm=na.rm),
                     mean = mean   (xx[[col]], na.rm=na.rm),
                     sd   = sd     (xx[[col]], na.rm=na.rm)
                   )
                 },
                 measurevar
  )
  
  # Rename the "mean" column   
  datac <- rename(datac, c("mean" = measurevar))
  
  datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
  
  # Confidence interval multiplier for standard error
  # Calculate t-statistic for confidence interval:
  # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
  ciMult <- qt(conf.interval/2 + .5, datac$N-1)
  datac$ci <- datac$se * ciMult
  
  return(datac)
}
```


## Prepare dataset

From the complete PYT52 2018/2019 dataset, we select root weight, which is fresh weight, and root number. 

```{r  warning=FALSE, message=FALSE}
H_A_Data <- readr::read_delim(here("data/18.CASS.PYT.52.IB_Harvest_Aerial.csv"), 
    ";", escape_double = FALSE, trim_ws = TRUE, 
    skip = 1)
shape=read.csv(here("data/average_shape_new.csv"))
root_data=dplyr::select(H_A_Data,clone=accession_name,rtwt, rtno)
root_data=completeFun(root_data, c("clone", "rtwt", "rtno"))
head(root_data)

```



```{r, warning=F}
trait=c("rtwt", "rtno")
for(i in 1:2){
  temp.sum=summarySE(data=root_data, measurevar = paste(trait[i]),
                     groupvars = "clone")
  colnames(temp.sum)=c("clone", "N", paste(trait[i]), "sd", "se", "ci")
  temp.sum=completeFun(temp.sum, c("clone", "N", paste(trait[i]), "sd", "se", "ci"))
  row.names(temp.sum)=NULL
  assign(paste("smmr.", trait[i], sep=""), temp.sum)
}

head(smmr.rtwt)
```
Construct the dataframe for clustering
```{r}
clus1=data.frame(rtwt=smmr.rtwt[3], rtno=smmr.rtno[3])
```
The dataframe needs to contain scaled values to do the clustering.
```{r}
clus2=scale(data.frame(rtwt=clus1$rtwt, rtno=clus1$rtno))

names=smmr.rtwt[1]
clus3=data.frame(clone=names$clone, clus1, clus2)

rownames(clus2)=names$clone
head(clus2)
```

Fit the k-means cluster, we use 5 clusters

```{r}
fit=kmeans(clus2, 5)
clus4=data.frame(clus3, fit$cluster)
head(clus4)

```
Write the dataframe to a .csv file
```{r}
clus5=clus4
is.num <- sapply(clus5, is.numeric)
clus5[is.num] <- lapply(clus5[is.num], round, 3)
#write.csv(file="200324_root_clusters.csv", x=clus5)
```

## Cluster plot

```{r , echo=FALSE}
clusplot(clus2, fit$cluster, color=T, shade=T, labels=2, lines=0, main="Clustering PYT52")

```

## Hierarchical clustering

We use a Euclidean distance matrix as an input for the clustering algorithm. Ward's minimum variance criterion minimizes the total within-cluster variance. 

```{r}
d=dist(clus2, method="euclidean")
H.fit=hclust(d, method="ward.D2")
```
Plot results in a dendrogram

```{r}
plot(H.fit)
groups=cutree(H.fit, k=5)
rect.hclust(H.fit, k=5, border="red") 
clus6=data.frame(clus3, H.fit$order)
```

